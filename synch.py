import os
import time
import json
import html
import logging
from datetime import datetime, timedelta, timezone
import requests
from markdown import markdown
from dotenv import load_dotenv

# ==== –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è ====
load_dotenv()

# ==== –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è ====
CLICKUP_TOKEN = os.getenv("CLICKUP_API_TOKEN")
CLICKUP_TEAM_ID = os.getenv("CLICKUP_TEAM_ID")
LOOKBACK_HOURS = int(os.getenv("CLICKUP_UPDATED_LOOKBACK_HOURS", "24"))
INTERCOM_TOKEN = os.getenv("INTERCOM_ACCESS_TOKEN")
INTERCOM_BASE = os.getenv("INTERCOM_REGION", "https://api.intercom.io").rstrip("/")
INTERCOM_VERSION = os.getenv("INTERCOM_VERSION", "Unstable")  # –ò–°–ü–†–ê–í–õ–ï–ù–û: Unstable –¥–ª—è internal articles
INTERCOM_OWNER_ID = int(os.getenv("INTERCOM_OWNER_ID"))
INTERCOM_AUTHOR_ID = int(os.getenv("INTERCOM_AUTHOR_ID"))
SYNC_STATE_FILE = os.getenv("SYNC_STATE_FILE", ".sync_state.json")
DRY_RUN = os.getenv("DRY_RUN", "false").lower() == "true"
FETCH_ALL = os.getenv("FETCH_ALL", "false").lower() == "true"
SPACE_ID = "90153590151"

IGNORED_LIST_IDS = ["901509433569", "901509402998"]

# ==== –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö ====
assert CLICKUP_TOKEN, "CLICKUP_API_TOKEN is required"
assert INTERCOM_TOKEN, "INTERCOM_ACCESS_TOKEN is required"
assert INTERCOM_OWNER_ID, "INTERCOM_OWNER_ID is required"
assert INTERCOM_AUTHOR_ID, "INTERCOM_AUTHOR_ID is required"

# ==== –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ====
logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s: %(message)s")

# ==== –°–µ—Å—Å–∏–∏ ====
cu = requests.Session()
cu.headers.update({
    "Authorization": CLICKUP_TOKEN,  # –£–ë–†–ê–ù–û Bearer - ClickUp –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –µ–≥–æ
    "Content-Type": "application/json"
})

ic = requests.Session()
ic.headers.update({
    "Authorization": f"Bearer {INTERCOM_TOKEN}",
    "Accept": "application/json",
    "Intercom-Version": INTERCOM_VERSION,
    "Content-Type": "application/json"
})

# ==== –£—Ç–∏–ª–∏—Ç—ã ====
def _load_state():
    if os.path.exists(SYNC_STATE_FILE):
        with open(SYNC_STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def _save_state(state: dict):
    with open(SYNC_STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

def _rate_limit_sleep(resp: requests.Response):
    if resp.status_code == 429:
        retry_after = int(resp.headers.get("Retry-After", "10"))
        logging.warning(f"Rate limited. Sleeping for {retry_after}s")
        time.sleep(retry_after)
        return True
    return False

# ==== ClickUp: –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –∑–∞–¥–∞—á –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ (–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–û) ====
def fetch_clickup_tasks(space_id: str, updated_after: datetime):
    """–ü–æ–ª—É—á–∞–µ–º –∑–∞–¥–∞—á–∏ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ - –±—ã—Å—Ç—Ä–µ–µ –∏ –ø—Ä–æ—â–µ"""
    base = f"https://api.clickup.com/api/v2/space/{space_id}/task"
    page = 0
    total = 0
    updated_gt = int(updated_after.timestamp() * 1000) if not FETCH_ALL else None
    
    while True:
        params = {
            "page": page,
            "include_subtasks": "true",
            "archived": "false",
            "order_by": "updated",
            "reverse": "true",
            "subtasks": "true",
            "limit": 100,
            "custom_fields": "true",  # –î–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è
            "tags[]": [],  # –ß—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Ç–µ–≥–∏
        }
        if updated_gt:
            params["updated_gt"] = updated_gt
            
        logging.info(f"Fetching tasks from space {space_id}, page {page}")
        r = cu.get(base, params=params)
        while _rate_limit_sleep(r):
            r = cu.get(base, params=params)
        r.raise_for_status()
        
        data = r.json()
        batch = data.get("tasks", [])
        if not batch:
            break
            
        for task in batch:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∏–∑ –ª–∏ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º—ã—Ö –ª–∏—Å—Ç–æ–≤
            list_id = task.get("list", {}).get("id")
            if list_id in IGNORED_LIST_IDS:
                logging.info(f"Skipping ignored list task: {task.get('name')}")
                continue
                
            total += 1
            yield task  # –£–∂–µ –ø–æ–ª–Ω–∞—è –∑–∞–¥–∞—á–∞ —Å description
            
        page += 1
    
    logging.info(f"Fetched {total} tasks from space {space_id}")

# ==== –£–ü–†–û–©–ï–ù–ù–ê–Ø —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è HTML (–¢–û–õ–¨–ö–û title + description) ====
def task_to_html(task: dict) -> str:
    name = task.get("name") or "(–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)"
    desc = task.get("description") or ""
    
    # –ü–†–û–°–¢–û–ô HTML: —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ
    body_html = markdown(desc) if desc else "<p><em>–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è</em></p>"
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
    if len(body_html) > 50000:
        body_html = body_html[:50000] + "<p><em>–û–ø–∏—Å–∞–Ω–∏–µ —É—Ä–µ–∑–∞–Ω–æ</em></p>"
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –∑–∞–¥–∞—á—É
    task_url = task.get("url") or f"https://app.clickup.com/t/{task.get('id')}"
    footer = f"""
    <hr>
    <p><small><a href="{html.escape(task_url)}" target="_blank">üîó –û—Ç–∫—Ä—ã—Ç—å –≤ ClickUp</a></small></p>
    """
    
    return f"<h1>{html.escape(name)}</h1>{body_html}{footer}"

# ==== Intercom: –ü–æ–∏—Å–∫ —Å—Ç–∞—Ç—å–∏ –ø–æ external_id (–ù–ê–î–ï–ñ–ù–ï–ï) ====
def find_article_by_external_id(external_id: str):
    """–ü–æ–∏—Å–∫ —Å—Ç–∞—Ç—å–∏ –ø–æ external_id - –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ —á–µ–º –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é"""
    endpoint = f"{INTERCOM_BASE}/internal_articles/search"
    params = {"query": f"external_id:{external_id}"}
    try:
        r = ic.get(endpoint, params=params)
        while _rate_limit_sleep(r):
            r = ic.get(endpoint, params=params)
        r.raise_for_status()
        
        data = r.json()
        articles = data.get("articles", [])
        if articles:
            logging.info(f"Found existing article by external_id {external_id}: ID {articles[0]['id']}")
            return articles[0]
        return None
    except Exception as e:
        logging.error(f"Error searching article by external_id '{external_id}': {e}")
        return None

# ==== Intercom: –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ ====
def create_internal_article(task: dict):
    task_id = task.get("id")
    endpoint = f"{INTERCOM_BASE}/internal_articles"
    title = task.get("name") or "(–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)"
    
    try:
        html_body = task_to_html(task)
        
        payload = {
            "title": title[:255],
            "body": html_body,
            "owner_id": INTERCOM_OWNER_ID,
            "author_id": INTERCOM_AUTHOR_ID,
            "locale": "en",
            "external_id": task_id,  # –ö–õ–Æ–ß–ï–í–û–ï: –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        }
        
        if DRY_RUN:
            logging.info(f"[DRY_RUN] Would CREATE: {title}")
            return None
        
        logging.info(f"Creating article: {title}")
        r = ic.post(endpoint, json=payload)
        logging.info(f"CREATE response: {r.status_code}")
        
        while _rate_limit_sleep(r):
            r = ic.post(endpoint, json=payload)
        
        if r.status_code in (200, 201):
            result = r.json()
            logging.info(f"‚úÖ CREATED: {title} (ID: {result.get('id')})")
            return result.get('id')
        else:
            logging.error(f"‚ùå CREATE failed: {r.status_code} {r.text[:200]}")
            return None
            
    except Exception as e:
        logging.error(f"‚ùå CREATE error for {task_id}: {e}")
        return None

# ==== Intercom: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ ====
def update_internal_article(article_id: str, task: dict):
    task_id = task.get("id")
    endpoint = f"{INTERCOM_BASE}/internal_articles/{article_id}"
    title = task.get("name") or "(–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)"
    
    try:
        html_body = task_to_html(task)
        
        payload = {
            "title": title[:255],
            "body": html_body,
            "owner_id": INTERCOM_OWNER_ID,
            "author_id": INTERCOM_AUTHOR_ID,
            "locale": "en",
            "external_id": task_id,
        }
        
        if DRY_RUN:
            logging.info(f"[DRY_RUN] Would UPDATE {article_id}: {title}")
            return
        
        logging.info(f"Updating article {article_id}: {title}")
        r = ic.put(endpoint, json=payload)
        logging.info(f"UPDATE response: {r.status_code}")
        
        while _rate_limit_sleep(r):
            r = ic.put(endpoint, json=payload)
        
        if r.status_code in (200, 201):
            logging.info(f"‚úÖ UPDATED: {title}")
        else:
            logging.error(f"‚ùå UPDATE failed: {r.status_code} {r.text[:200]}")
            
    except Exception as e:
        logging.error(f"‚ùå UPDATE error for {task_id}: {e}")

# ==== –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è upsert ====
def upsert_internal_article(task: dict):
    task_id = task.get("id")
    title = task.get("name") or "(–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)"
    
    # –ò—â–µ–º –ø–æ external_id
    existing = find_article_by_external_id(task_id)
    
    if existing:
        update_internal_article(existing["id"], task)
    else:
        create_internal_article(task)

# ==== –ì–ª–∞–≤–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å ====
def main():
    state = _load_state()
    last_sync_iso = state.get("last_sync_iso")
    if last_sync_iso and not FETCH_ALL:
        updated_after = datetime.fromisoformat(last_sync_iso)
    else:
        updated_after = datetime.now(timezone.utc) - timedelta(hours=LOOKBACK_HOURS)
    
    logging.info(f"üöÄ Starting sync after {updated_after.isoformat()}")
    count = 0
    
    try:
        for task in fetch_clickup_tasks(SPACE_ID, updated_after):
            try:
                upsert_internal_article(task)
                count += 1
                logging.info(f"Processed {count}: {task.get('name')[:50]}...")
            except Exception as e:
                logging.error(f"Failed task {task.get('id')}: {e}")
                continue
    except Exception as e:
        logging.error(f"Sync error: {e}")
    
    now_iso = datetime.now(timezone.utc).isoformat()
    state["last_sync_iso"] = now_iso
    _save_state(state)
    logging.info(f"‚úÖ Done! Synced {count} articles")

if __name__ == "__main__":
    main()
